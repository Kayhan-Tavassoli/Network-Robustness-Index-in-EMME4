{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Important Note:\n",
    "        I have made modifications to the code in a text editor, without running it (as I don't have access\n",
    "        to EMME4 anymore). so, some errors are likely to arise.\n",
    "        Please contact me upon occurrence of errors of any kind.\n",
    "'''\n",
    "\n",
    "import datetime\n",
    "import os \n",
    "#There is no need to import inro.modeller; it's preloaded in EMME4 Notebook.\n",
    "\n",
    "def sortByNRI(source, demandMatrix, CPU, links2disrupt = [], disruptBothDirs = False):\n",
    "    \n",
    "    '''\n",
    "    sortByNRI ranks links in order of their Network Robustness Index (NRI). \n",
    "    \n",
    "    Requires:\n",
    "    source: \n",
    "        Identifier of the original scenario wherein the intact network lies (it makes a copy of the\n",
    "        original scenario to remove links from, so there's nothing to worry about.)\n",
    "    demandMatrix: \n",
    "        Identifier of the demand matrix to be assigned to the network\n",
    "    CPU:\n",
    "        Number of CPU cores to utilize\n",
    "    links2disrupt (optional): \n",
    "        Specific links to be disrupted; enter as follows -> [(i,j), (k,m), ... ]\n",
    "    disruptBothDirs (optional):\n",
    "        Whether to disrupt both directions in two-way roadways\n",
    "    \n",
    "    Returns: a pandas Series containing links ranked in order of their NRI value\n",
    "    '''\n",
    "\n",
    "    \n",
    "    '''Initialization'''\n",
    "    \n",
    "    #in case of considerably large networks, we cannot afford to save results in DataFrames using RAM. \n",
    "    #so as to avoid \"out of memory\" error:\n",
    "    #directories for text files to record the results in, using \"with open(...)\" \n",
    "    datetimeStr = str(datetime.datetime.now()).replace(':', '_')\n",
    "    \n",
    "    spttFileDir = datetimeStr + \" spttFile.txt\"\n",
    "    totalTTFileDir = datetimeStr + \" totalTTFile.txt\n",
    "    asLinkVolFileDir = datetimeStr + \" asLinkVolFile.txt\"\n",
    "    \n",
    "    scenID = source + 1000\n",
    "    _m = inro.modeller.Modeller()\n",
    "    emmebank = _m.emmebank\n",
    "    desktop = _m.desktop\n",
    "    \n",
    "    \n",
    "    asLinkVol = {} #dictionary to record traffic volumes in links in different scenarios\n",
    "    totalTT = {} #dictionary to record total travel time in different scenarios\n",
    "    spttMat = {} #dictionary to record shortest path travel time between ODs in different scenarios\n",
    "    hist = [] #links that are disrupted as the opposing direction of a previously disrupted link\n",
    "    \n",
    "    #ensuring that there is no attribute with identifier \"@alvol\" created previously:\n",
    "    try:\n",
    "        _m.tool(\"inro.emme.data.extra_attribute.delete_extra_attribute\")(\"@alvol\") \n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "    #creating an attribute to save link volumes after assignment:\n",
    "    alvol = _m.tool(\"inro.emme.data.extra_attribute.create_extra_attribute\")(extra_attribute_type=\"LINK\",\n",
    "                        extra_attribute_name = \"@alvol\",\n",
    "                        extra_attribute_description = \"link volumes after assignment\",\n",
    "                        overwrite = True) \n",
    "    \n",
    "    #ensuring that there is no matrix with identifier \"mf30\" created previously:\n",
    "    try: \n",
    "        _m.tool(\"inro.emme.data.matrix.delete_matrix\")(\"mf30\")\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "    #creating a matrix to save OD travel times on shortest paths:\n",
    "    sptt = _m.tool(\"inro.emme.data.matrix.create_matrix\")(matrix_id=\"mf30\",\n",
    "                            matrix_name = \"sptt\",\n",
    "                            matrix_description = \"O-D travel times on shortest paths\",\n",
    "                            default_value = 0) \n",
    "    \n",
    "    demandNumpyMatrix = emmebank.matrix(demandMatrix).get_data().to_numpy() #for matrix multiplication\n",
    "    \n",
    "    #ensuring that there is no scenario with identifier scenID created previously:\n",
    "    try: \n",
    "        emmebank.delete_scenario(scenID)\n",
    "    except: \n",
    "        pass\n",
    "    \n",
    "    #a copy of the original scenario to disrupt links in:\n",
    "    emmebank.copy_scenario(source,scenID)\n",
    "    scen = emmebank.scenario(scenID)\n",
    "    \n",
    "    #specifying the assignment tool (in JSON):\n",
    "    assign = _m.tool('inro.emme.traffic_assignment.standard_traffic_assignment')\n",
    "    null = None\n",
    "    specs = '''{\n",
    "        \"type\": \"STANDARD_TRAFFIC_ASSIGNMENT\",\n",
    "        \"classes\": [\n",
    "            {\n",
    "                \"mode\": \"c\",\n",
    "                \"demand\": \"''' + demandMatrix + '''\" ,\n",
    "                \"generalized_cost\": null,\n",
    "                \"results\": {\n",
    "                    \"link_volumes\": \"@alvol\",\n",
    "                    \"turn_volumes\": null,\n",
    "                    \"od_travel_times\": {\n",
    "                        \"shortest_paths\": \"mf30\"\n",
    "                    }\n",
    "                },\n",
    "                \"analysis\": {\n",
    "                    \"analyzed_demand\": null,\n",
    "                    \"results\": {\n",
    "                        \"od_values\": null,\n",
    "                        \"selected_link_volumes\": null,\n",
    "                        \"selected_turn_volumes\": null\n",
    "                    }\n",
    "                }\n",
    "            }\n",
    "        ],\n",
    "        \"performance_settings\": {\n",
    "            \"number_of_processors\": ''' + str(CPU) + '''\n",
    "        },\n",
    "        \"background_traffic\": null,\n",
    "        \"path_analysis\": null,\n",
    "        \"cutoff_analysis\": null,\n",
    "        \"traversal_analysis\": null,\n",
    "        \"stopping_criteria\": {\n",
    "            \"max_iterations\": 100,\n",
    "            \"relative_gap\": 0,\n",
    "            \"best_relative_gap\": 0.1,\n",
    "            \"normalized_gap\": 0.05\n",
    "        }\n",
    "    }'''\n",
    "    \n",
    "    '''traffic assignment to the base scenario'''\n",
    "    assign(specification = specs, scenario = scen)\n",
    "    #recording the results:\n",
    "    alvol = scen.get_attribute_values(\"LINK\",[\"@alvol\"])\n",
    "    linkVol = {} #dictionary to record traffic volumes in links\n",
    "    for i in alvol[0]:\n",
    "        for j in alvol[0][i]:\n",
    "            linkVol[(i,j)] = alvol[1][alvol[0][i][j]]\n",
    "    \n",
    "    asLinkVol['base'] = linkVol\n",
    "    totalTT['base'] = (sptt.get_data().to_numpy() * demandNumpyMatrix).sum()\n",
    "    spttMat['base'] =  sptt.get_data()\n",
    "    \n",
    "    with open(spttFileDir, 'a+') as f:\n",
    "        f.write('{\"base\" : ' + str(sptt.get_data()))\n",
    "    with open(totalTTFile, 'a+') as f:\n",
    "        f.write('{\"base\" : ' + str((sptt.get_data().to_numpy() * demandNumpyMatrix).sum()))\n",
    "    with open(asLinkVolFile, 'a+') as f:\n",
    "        f.write('{\"base\" : ' + str(linkVol))\n",
    "    \n",
    "    '''disrupt, assign, reload the intact network'''\n",
    "    with inro.modeller.logbook_trace(\"Sequential Assignment\"):\n",
    "        \n",
    "        #if the user hasn't inputted any specific links to disrupt, go through the whole network.\n",
    "        if links2disrupt == []: \n",
    "            links = scen.get_network().links()\n",
    "        else:\n",
    "            links = [scen.get_network().link(i,j) for i,j in links2disrupt]\n",
    "        \n",
    "        for link in links:\n",
    "            if disruptBothDirs:\n",
    "                #skip link if it has been already disrupted as an opposing direction:\n",
    "                if link in hist:\n",
    "                        continue\n",
    "                #if link belongs to a two-way roadway, append the opposing direction to hist:\n",
    "                if link.reverse_link != None: \n",
    "                    linkDirs = [link , link.reverse_link]\n",
    "                    hist.append(link.reverse_link) \n",
    "                    twoWay = True\n",
    "            else:\n",
    "                linkDirs = [link]\n",
    "                twoWay = False\n",
    "\n",
    "            #disrupting link(s):\n",
    "            for linkDir in linkDirs: \n",
    "                i_node = linkDir.i_node\n",
    "                j_node = linkDir.j_node\n",
    "                _m.tool(\"inro.emme.data.network.base.delete_links\")(selection=\"link=\" + str(i_node) + ',' \n",
    "                                                                    + str(j_node),condition=\"cascade\", \n",
    "                                                                    scenario=scen)\n",
    "            #assigning traffic to the modified network:\n",
    "            assign(specification = specs, scenario = scen)\n",
    "            #recording the results:\n",
    "            alvol = scen.get_attribute_values(\"LINK\",[\"@alvol\"])\n",
    "            linkVol = {}\n",
    "            for i in alvol[0]:\n",
    "                for j in alvol[0][i]:\n",
    "                    linkVol[(i,j)] = alvol[1][alvol[0][i][j]]\n",
    "\n",
    "            asLinkVol[(int(i_node.id),int(j_node.id))] = linkVol\n",
    "            asLinkVol[(int(j_node.id),int(i_node.id))] = linkVol\n",
    "            \n",
    "            totalTT[(int(i_node.id),int(j_node.id))] = (sptt.get_data().to_numpy() \n",
    "                                                        * demandNumpyMatrix).sum() \n",
    "            totalTT[(int(j_node.id),int(i_node.id))] = (sptt.get_data().to_numpy() \n",
    "                                                        * demandNumpyMatrix).sum()\n",
    "\n",
    "            spttMat[(int(i_node.id),int(j_node.id))] = sptt.get_data()\n",
    "            spttMat[(int(j_node.id),int(i_node.id))] = sptt.get_data()\n",
    "            \n",
    "            with open(spttFileDir, 'a+') as f:\n",
    "                f.write(', \"' + str((int(i_node.id),int(j_node.id))) + '\" : ' + str(sptt.get_data()))\n",
    "            with open(totalTTFile, 'a+') as f:\n",
    "                f.write(', \"' + str((int(i_node.id),int(j_node.id))) + '\" : ' \n",
    "                        + str((sptt.get_data().to_numpy() * demandNumpyMatrix).sum()))\n",
    "            with open(asLinkVolFile, 'a+') as f:\n",
    "                f.write(', \"' + str((int(i_node.id),int(j_node.id))) + '\" : ' + str(linkVol))\n",
    "            \n",
    "            if disruptBothDirs:\n",
    "                if twoWay:\n",
    "                    with open(spttFileDir, 'a+') as f:\n",
    "                        f.write(', \"' + str((int(j_node.id),int(i_node.id)))+'\" : ' \n",
    "                                + str(sptt.get_data()))\n",
    "                    with open(totalTTFile, 'a+') as f:\n",
    "                        f.write(', \"' + str((int(j_node.id),int(i_node.id)))+'\" : '\n",
    "                                + str((sptt.get_data().to_numpy() * demandNumpyMatrix).sum()))\n",
    "                    with open(asLinkVolFile, 'a+') as f:\n",
    "                        f.write(', \"' + str((int(j_node.id),int(i_node.id)))+'\" : '+str(linkVol))\n",
    "                \n",
    "            emmebank.delete_scenario(scenID)\n",
    "            emmebank.copy_scenario(source,scenID)\n",
    "    \n",
    "    with open(spttFileDir, 'a+') as f:\n",
    "        f.write('}')\n",
    "    with open(asLinkVolFile, 'a+') as f:\n",
    "        f.write('}')\n",
    "    with open(totalTTFile, 'a+') as f:\n",
    "        f.write('}')\n",
    "    \n",
    "    #calculation of NRI:\n",
    "    with open(totalTTFile, 'r+') as f: \n",
    "        totalTT_Series = pd.Series(eval(f))\n",
    "    NRI_Series = totalTT_Series.subtract(totalTT_Series['base'])\n",
    "    NRI_Series.drop('base', inplace = True)\n",
    "    NRI_Series.sort_values(ascending = False, inplace = True)\n",
    "    \n",
    "    print ('Detailed result files are saved in ' + os.getcwd())\n",
    "    \n",
    "    return NRI_Series\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
